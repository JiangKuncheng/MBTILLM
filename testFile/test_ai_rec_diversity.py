#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•aiRec=falseæ˜¯å¦çœŸçš„è®©æ¯æ¬¡è·å–çš„å†…å®¹ä¸åŒ
"""

import asyncio
import json
from datetime import datetime
from collections import Counter

async def test_ai_rec_diversity():
    """æµ‹è¯•aiRec=falseæ˜¯å¦çœŸçš„è®©æ¯æ¬¡è·å–çš„å†…å®¹ä¸åŒ"""
    print("ğŸ§ª æµ‹è¯•aiRec=falseçš„å†…å®¹å¤šæ ·æ€§")
    print("=" * 60)
    
    try:
        from sohu_client import sohu_client
        
        print("ğŸ“‹ æµ‹è¯•1: è¿ç»­å¤šæ¬¡è·å–å†…å®¹ï¼Œæ£€æŸ¥æ˜¯å¦ç›¸åŒ")
        print("-" * 50)
        
        # è¿ç»­è·å–5æ¬¡ï¼Œæ¯æ¬¡10æ¡å†…å®¹
        all_fetches = []
        content_ids_per_fetch = []
        
        for fetch_round in range(1, 6):
            print(f"\nğŸ”„ ç¬¬{fetch_round}æ¬¡è·å–:")
            
            async with sohu_client as client:
                result = await client.get_article_list(
                    page_num=1,
                    page_size=10,
                    state="OnShelf",
                    site_id=11
                )
                
                if result.get("code") == 200 and "data" in result:
                    data = result["data"]
                    if isinstance(data, list):
                        articles = data
                    elif isinstance(data, dict):
                        articles = data.get("data", [])
                        if not articles and "list" in data:
                            articles = data.get("list", [])
                    else:
                        articles = []
                    
                    if articles:
                        # æå–å†…å®¹IDå’Œæ ‡é¢˜
                        content_info = []
                        for article in articles:
                            content_info.append({
                                'id': article.get('id'),
                                'title': article.get('title', 'æ— æ ‡é¢˜')[:30],
                                'type': article.get('type'),
                                'state': article.get('state'),
                                'auditState': article.get('auditState')
                            })
                        
                        all_fetches.append(content_info)
                        content_ids = [article.get('id') for article in articles]
                        content_ids_per_fetch.append(content_ids)
                        
                        print(f"   âœ… æˆåŠŸè·å– {len(articles)} æ¡å†…å®¹")
                        print(f"   ğŸ“Š å†…å®¹ID: {content_ids}")
                        print(f"   ğŸ“ å‰3æ¡æ ‡é¢˜:")
                        for i, info in enumerate(content_info[:3], 1):
                            print(f"      {i}. ID:{info['id']} - {info['title']}...")
                    else:
                        print(f"   âŒ æ²¡æœ‰è·å–åˆ°å†…å®¹")
                else:
                    print(f"   âŒ è·å–å¤±è´¥: {result.get('msg')}")
        
        print("\nğŸ“‹ æµ‹è¯•2: åˆ†æå†…å®¹é‡å¤æƒ…å†µ")
        print("-" * 50)
        
        if all_fetches:
            # ç»Ÿè®¡æ‰€æœ‰å†…å®¹ID
            all_content_ids = []
            for fetch_ids in content_ids_per_fetch:
                all_content_ids.extend(fetch_ids)
            
            # ç»Ÿè®¡æ¯ä¸ªIDå‡ºç°çš„æ¬¡æ•°
            id_counter = Counter(all_content_ids)
            
            print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
            print(f"   æ€»è·å–æ¬¡æ•°: {len(all_fetches)}")
            print(f"   æ€»å†…å®¹æ¡æ•°: {len(all_content_ids)}")
            print(f"   å”¯ä¸€å†…å®¹æ•°: {len(id_counter)}")
            print(f"   é‡å¤å†…å®¹æ•°: {len(all_content_ids) - len(id_counter)}")
            
            # æ˜¾ç¤ºé‡å¤çš„å†…å®¹
            repeated_ids = [id for id, count in id_counter.items() if count > 1]
            if repeated_ids:
                print(f"\nğŸ”„ é‡å¤å‡ºç°çš„å†…å®¹ID:")
                for content_id in repeated_ids:
                    count = id_counter[content_id]
                    print(f"   ID {content_id}: å‡ºç° {count} æ¬¡")
                    
                    # æ˜¾ç¤ºè¿™ä¸ªå†…å®¹åœ¨ä¸åŒè·å–ä¸­çš„ä¿¡æ¯
                    for i, fetch in enumerate(all_fetches):
                        for content in fetch:
                            if content['id'] == content_id:
                                print(f"     ç¬¬{i+1}æ¬¡: {content['title']}...")
            else:
                print(f"\nâœ… æ²¡æœ‰é‡å¤å†…å®¹ï¼æ¯æ¬¡è·å–éƒ½ä¸åŒ")
            
            # è®¡ç®—å¤šæ ·æ€§æŒ‡æ ‡
            diversity_ratio = len(id_counter) / len(all_content_ids) * 100
            print(f"\nğŸ“ˆ å†…å®¹å¤šæ ·æ€§: {diversity_ratio:.1f}%")
            
            if diversity_ratio > 80:
                print("   ğŸ‰ å†…å®¹å¤šæ ·æ€§å¾ˆé«˜ï¼aiRec=falseå·¥ä½œæ­£å¸¸")
            elif diversity_ratio > 50:
                print("   ğŸ‘ å†…å®¹å¤šæ ·æ€§ä¸­ç­‰ï¼ŒaiRec=falseéƒ¨åˆ†æœ‰æ•ˆ")
            else:
                print("   âš ï¸  å†…å®¹å¤šæ ·æ€§è¾ƒä½ï¼ŒaiRec=falseå¯èƒ½æ— æ•ˆ")
        
        print("\nğŸ“‹ æµ‹è¯•3: æ£€æŸ¥è¯·æ±‚å‚æ•°")
        print("-" * 50)
        
        # æ£€æŸ¥æœç‹å®¢æˆ·ç«¯çš„è¯·æ±‚å‚æ•°
        async with sohu_client as client:
            print("ğŸ” æ£€æŸ¥æœç‹å®¢æˆ·ç«¯çš„è¯·æ±‚å‚æ•°:")
            print(f"   åŸºç¡€URL: {client.base_url}")
            print(f"   è®¤è¯çŠ¶æ€: {'å·²è®¤è¯' if client.access_token else 'æœªè®¤è¯'}")
            print(f"   åŠ å¯†çŠ¶æ€: {'å·²å‡†å¤‡' if client.hmac_key and client.aes_key else 'æœªå‡†å¤‡'}")
            
            # æ¨¡æ‹Ÿä¸€æ¬¡è¯·æ±‚çš„å‚æ•°æ„å»º
            params = {
                "pageNum": 1,
                "pageSize": 10,
                "aiRec": "false",
                "state": "OnShelf",
                "siteId": 11
            }
            
            print(f"\nğŸ“ è¯·æ±‚å‚æ•°:")
            for key, value in params.items():
                print(f"   {key}: {value}")
            
            print(f"\nğŸ”‘ å…³é”®å‚æ•°éªŒè¯:")
            print(f"   aiRec: {params.get('aiRec')} {'âœ…' if params.get('aiRec') == 'false' else 'âŒ'}")
            print(f"   pageSize: {params.get('pageSize')} {'âœ…' if params.get('pageSize') >= 10 else 'âŒ'}")
        
        print("\nğŸ¯ æµ‹è¯•æ€»ç»“")
        print("-" * 50)
        if all_fetches:
            unique_ratio = len(set(all_content_ids)) / len(all_content_ids) * 100
            print(f"âœ… å†…å®¹å”¯ä¸€æ€§: {unique_ratio:.1f}%")
            print(f"âœ… æ€»è·å–æ¬¡æ•°: {len(all_fetches)}")
            print(f"âœ… æ€»å†…å®¹æ¡æ•°: {len(all_content_ids)}")
            
            if unique_ratio > 80:
                print("ğŸ‰ aiRec=falseå·¥ä½œæ­£å¸¸ï¼Œæ¯æ¬¡è·å–å†…å®¹éƒ½ä¸åŒï¼")
            else:
                print("âš ï¸  aiRec=falseå¯èƒ½æ— æ•ˆï¼Œå»ºè®®æ£€æŸ¥æ¥å£é…ç½®")
        else:
            print("âŒ æ²¡æœ‰è·å–åˆ°ä»»ä½•å†…å®¹ï¼Œéœ€è¦æ£€æŸ¥æ¥å£è¿æ¥")
        
        print("\nâœ¨ aiRecå¤šæ ·æ€§æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(test_ai_rec_diversity()) 