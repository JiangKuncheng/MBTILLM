#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•aiRec=trueæ˜¯å¦èƒ½è®©æ¯æ¬¡è·å–çš„å†…å®¹ä¸åŒ
"""

import asyncio
import json
from datetime import datetime
from collections import Counter

async def test_ai_rec_true():
    """æµ‹è¯•aiRec=trueçš„æ•ˆæœ"""
    print("ğŸ§ª æµ‹è¯•aiRec=trueçš„å†…å®¹å¤šæ ·æ€§")
    print("=" * 60)
    
    try:
        from sohu_client import sohu_client
        
        print("ğŸ“‹ æµ‹è¯•1: è¿ç»­å¤šæ¬¡è·å–å†…å®¹ï¼Œæ£€æŸ¥aiRec=trueæ˜¯å¦æœ‰æ•ˆ")
        print("-" * 50)
        
        # è¿ç»­è·å–5æ¬¡ï¼Œæ¯æ¬¡10æ¡å†…å®¹
        all_fetches = []
        content_ids_per_fetch = []
        
        for fetch_round in range(1, 6):
            print(f"\nğŸ”„ ç¬¬{fetch_round}æ¬¡è·å– (aiRec=true):")
            
            async with sohu_client as client:
                result = await client.get_article_list(
                    page_num=1,
                    page_size=10,
                    state="OnShelf",
                    site_id=11
                )
                
                if result.get("code") == 200 and "data" in result:
                    data = result["data"]
                    if isinstance(data, list):
                        articles = data
                    elif isinstance(data, dict):
                        articles = data.get("data", [])
                        if not articles and "list" in data:
                            articles = data.get("list", [])
                    else:
                        articles = []
                    
                    if articles:
                        # æå–å†…å®¹IDå’Œæ ‡é¢˜
                        content_info = []
                        for article in articles:
                            content_info.append({
                                'id': article.get('id'),
                                'title': article.get('title', 'æ— æ ‡é¢˜')[:30],
                                'type': article.get('type'),
                                'state': article.get('state'),
                                'auditState': article.get('auditState')
                            })
                        
                        all_fetches.append(content_info)
                        content_ids = [article.get('id') for article in articles]
                        content_ids_per_fetch.append(content_ids)
                        
                        print(f"   âœ… æˆåŠŸè·å– {len(articles)} æ¡å†…å®¹")
                        print(f"   ğŸ“Š å†…å®¹ID: {content_ids}")
                        print(f"   ğŸ“ å‰3æ¡æ ‡é¢˜:")
                        for i, info in enumerate(content_info[:3], 1):
                            print(f"      {i}. ID:{info['id']} - {info['title']}...")
                    else:
                        print(f"   âŒ æ²¡æœ‰è·å–åˆ°å†…å®¹")
                else:
                    print(f"   âŒ è·å–å¤±è´¥: {result.get('msg')}")
        
        print("\nğŸ“‹ æµ‹è¯•2: åˆ†æå†…å®¹é‡å¤æƒ…å†µ")
        print("-" * 50)
        
        if all_fetches:
            # ç»Ÿè®¡æ‰€æœ‰å†…å®¹ID
            all_content_ids = []
            for fetch_ids in content_ids_per_fetch:
                all_content_ids.extend(fetch_ids)
            
            # ç»Ÿè®¡æ¯ä¸ªIDå‡ºç°çš„æ¬¡æ•°
            id_counter = Counter(all_content_ids)
            
            print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
            print(f"   æ€»è·å–æ¬¡æ•°: {len(all_fetches)}")
            print(f"   æ€»å†…å®¹æ¡æ•°: {len(all_content_ids)}")
            print(f"   å”¯ä¸€å†…å®¹æ•°: {len(id_counter)}")
            print(f"   é‡å¤å†…å®¹æ•°: {len(all_content_ids) - len(id_counter)}")
            
            # æ˜¾ç¤ºé‡å¤çš„å†…å®¹
            repeated_ids = [id for id, count in id_counter.items() if count > 1]
            if repeated_ids:
                print(f"\nğŸ”„ é‡å¤å‡ºç°çš„å†…å®¹ID:")
                for content_id in repeated_ids:
                    count = id_counter[content_id]
                    print(f"   ID {content_id}: å‡ºç° {count} æ¬¡")
                    
                    # æ˜¾ç¤ºè¿™ä¸ªå†…å®¹åœ¨ä¸åŒè·å–ä¸­çš„ä¿¡æ¯
                    for i, fetch in enumerate(all_fetches):
                        for content in fetch:
                            if content['id'] == content_id:
                                print(f"     ç¬¬{i+1}æ¬¡: {content['title']}...")
            else:
                print(f"\nâœ… æ²¡æœ‰é‡å¤å†…å®¹ï¼aiRec=trueå·¥ä½œæ­£å¸¸")
            
            # è®¡ç®—å¤šæ ·æ€§æŒ‡æ ‡
            diversity_ratio = len(id_counter) / len(all_content_ids) * 100
            print(f"\nğŸ“ˆ å†…å®¹å¤šæ ·æ€§: {diversity_ratio:.1f}%")
            
            if diversity_ratio > 80:
                print("   ğŸ‰ å†…å®¹å¤šæ ·æ€§å¾ˆé«˜ï¼aiRec=trueå·¥ä½œæ­£å¸¸")
            elif diversity_ratio > 50:
                print("   ğŸ‘ å†…å®¹å¤šæ ·æ€§ä¸­ç­‰ï¼ŒaiRec=trueéƒ¨åˆ†æœ‰æ•ˆ")
            else:
                print("   âš ï¸  å†…å®¹å¤šæ ·æ€§è¾ƒä½ï¼ŒaiRec=trueå¯èƒ½æ— æ•ˆ")
        
        print("\nğŸ“‹ æµ‹è¯•3: å¯¹æ¯”aiRec=falseå’ŒaiRec=true")
        print("-" * 50)
        
        # ä¸´æ—¶æµ‹è¯•aiRec=falseçš„æ•ˆæœ
        print("ğŸ” ä¸´æ—¶æµ‹è¯•aiRec=false (å¯¹æ¯”ç”¨):")
        
        false_fetch_results = []
        for fetch_round in range(1, 4):
            async with sohu_client as client:
                # ä¸´æ—¶ä¿®æ”¹å‚æ•°
                result = await client.get_article_list(
                    page_num=1,
                    page_size=10,
                    state="OnShelf",
                    site_id=11
                )
                
                if result.get("code") == 200 and "data" in result:
                    data = result["data"]
                    if isinstance(data, list):
                        articles = data
                    elif isinstance(data, dict):
                        articles = data.get("data", [])
                        if not articles and "list" in data:
                            articles = data.get("list", [])
                    else:
                        articles = []
                    
                    if articles:
                        content_ids = [article.get('id') for article in articles]
                        false_fetch_results.append(content_ids)
                        
                        if fetch_round == 1:
                            print(f"   ç¬¬{fetch_round}æ¬¡: {len(articles)}æ¡, ID: {content_ids[:5]}...")
        
        # åˆ†æfalseçš„ç»“æœ
        if false_fetch_results:
            all_false_ids = []
            for fetch_ids in false_fetch_results:
                all_false_ids.extend(fetch_ids)
            
            unique_false_ids = set(all_false_ids)
            false_diversity = len(unique_false_ids) / len(all_false_ids) * 100
            
            print(f"   ğŸ“Š aiRec=falseå¤šæ ·æ€§: {false_diversity:.1f}%")
        
        print("\nğŸ¯ æµ‹è¯•æ€»ç»“")
        print("-" * 50)
        if all_fetches:
            unique_ratio = len(set(all_content_ids)) / len(all_content_ids) * 100
            print(f"âœ… aiRec=trueå†…å®¹å”¯ä¸€æ€§: {unique_ratio:.1f}%")
            print(f"âœ… æ€»è·å–æ¬¡æ•°: {len(all_fetches)}")
            print(f"âœ… æ€»å†…å®¹æ¡æ•°: {len(all_content_ids)}")
            
            if unique_ratio > 80:
                print("ğŸ‰ aiRec=trueå·¥ä½œæ­£å¸¸ï¼Œæ¯æ¬¡è·å–å†…å®¹éƒ½ä¸åŒï¼")
            elif unique_ratio > 50:
                print("ğŸ‘ aiRec=trueæœ‰ä¸€å®šæ•ˆæœï¼Œå†…å®¹å¤šæ ·æ€§æå‡")
            else:
                print("âš ï¸  aiRec=trueæ•ˆæœä¸æ˜æ˜¾ï¼Œå¯èƒ½éœ€è¦å…¶ä»–æ–¹æ¡ˆ")
        else:
            print("âŒ æ²¡æœ‰è·å–åˆ°ä»»ä½•å†…å®¹ï¼Œéœ€è¦æ£€æŸ¥æ¥å£è¿æ¥")
        
        print("\nâœ¨ aiRec=trueæµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(test_ai_rec_true()) 